---
layout: post
title: "面试知识梳理"
categories:
- 面试
tags:
- 面试准备  
- 知识梳理
---

[TOC]


##数据库篇
---
###一、索引
---
####*索引的分类* 

1.	根据索引的顺序与数据的物理顺序是否一致可以分为聚簇索引和非聚簇索引。
    * 聚簇索引：表数据按照索引的顺序来存储的。对于聚集索引，叶子结点即存储了真实的数据行，不再有另外单独的数据页。
    * 非聚簇索引：表数据存储顺序与索引顺序无关。对于非聚集索引，叶结点包含索引字段值及指向数据页数据行的逻辑指针（InnoDB里是P_K），该层紧邻数据页，其行数量与数据表行数据量一致。
2.	按照索引的数据结构来分的话，可以分为b-tree索引、hash索引、r-tree索引和全文索引。
    * full-text索引：mysql中只有MyISAM存储引擎支持。目前也只是支持char、varchar和text字段。全文索引的原理主要是分词和倒排索引。Myisam里的分词只支持英文。
    * b-tree索引：b-tree在 innodb里，有两种形态：一是primary key形态，其leaf node里存放的是数据，而且不仅存放了索引键的数据，还存放了其他字段的数据（对应于聚簇索引）；二是secondary index，其leaf node和普通的b-tree差不多，只是还存放了指向主键的信息（对应于非聚簇索引）
    * b+tree索引：b+tree内节点不存储data，只存储key；叶子节点不存储指针。一般经过优化，b+tree都是带有顺序访问指针，方便范围查找
    * hash索引：由于存放的是hash值，所以仅支持<=>以及in操作；hash索引无法通过操作索引来排序；Hash 索引在任何时候都不能避免表扫描。
    * r-tree索引：略

####*为什么数据库索引采用b+tree索引？*
 &emsp;&emsp;这要从计算机存储原理和操作系统相关知识说起。因为数据表的索引比较大，不能常驻内存，所以以文件形式存储在磁盘中。所以当查询数据的时候就需要I/O操作。高效率查询的目标是较少I/O次数。一次I/O一般读取一页（一般为4k）大小的数据(局部性原理)。如此，在B-树中，每当申请一个新结点时，就以页的大小来申请。也就是说一次I/o可以读取一个一个结点（包含很多key）的数据；而在红黑树结构结构中，逻辑相邻的结点物理上不一定相邻，就是说，读取同等的数据需要多次I/O。所以选择B-树效率更好。
那为何最终选了B+树呢？
&emsp;&emsp;因为B+树内节点去掉了data域，因此可以拥有更大的出度，就是说一个结点可以存储更多的内结点，那么I/O效率更高。

####*索引的存储*
 &emsp;&emsp;一条索引记录中包含的基本信息包括：键值（即你定义索引时指定的所有字段的值）+逻辑指针（指向数据页或者另一索引页）。
 ![](1.png)
  &emsp;&emsp;当你为一张空表创建索引时，数据库系统将为你分配一个索引页，该索引页在你插入数据前一直是空的。此页此时既是根结点，也是叶结点。每当你往表中插入一行数据，数据库系统即向此根结点中插入一行索引记录。当根结点满时，数据库系统大抵按以下步骤进行分裂：<br>
1) 创建两个儿子结点<br>
2) 将原根结点中的数据近似地拆成两半，分别写入新的两个儿子结点<br>
3) 根结点中加上指向两个儿子结点的指针<br>

1.  聚簇索引的存储
在聚集索引中，叶结点也即数据结点，所有数据行的存储顺序与索引的存储顺序一致。
 ![](2.png)
2. 非聚簇索引的存储
聚集索引是一种稀疏索引，数据页上一级的索引页存储的是页指针，而不是行指针。而对于非聚集索引，则是密集索引，在数据页的上一级索引页它为每一个数据行存储一条索引记录。
 ![](3.png)

####*覆盖索引*
  &emsp;&emsp;索引覆盖是这样一种索引策略：当某一查询中包含的所需字段皆包含于一个索引中，此时索引将大大提高查询性能。<br>
  &emsp;&emsp;如果你在若干个字段上创建了一个复合的非聚集索引，且你的查询中所需Select字段及Where,Order By,Group By,Having子句中所涉及的字段都包含在索引中，则只搜索索引页即可满足查询，而不需要访问数据页。由于非聚集索引的叶结点包含所有数据行中的索引列值，使用这些结点即可返回真正的数据，这种情况称之为“索引覆盖”。

####*索引使用注意点*
mysql里sql语句值得注意的地方有：

- blob和text字段仅支持前缀索引. 
- 使用!=以及<>不等于的时候mysql不使用索引. 
- 当在字段使用函数的时候,mysql无法使用索引,在join的时候条件字段类型不一致的时候,mysql无法使用索引,在组合索引里使用非第一个索引时也不使用索引. 
- 在使用like的时候,以%开头,即"%***"的时候无法使用索引,在使用or的时候,要求or前后字段都有索引.


###二、存储引擎
---
####*InnoDB机制*
1.	事务隔离级别
在数据库操作中，为了有效保证并发读取数据的正确性，提出的事务隔离级别。我们的数据库锁，也是为了构建这些隔离级别存在的。
    * 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据
    *	提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)
    *	可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读
    *	串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。

    Read Uncommitted这种级别，数据库一般都不会用，而且任何操作都不会加锁，这里就不讨论了。<br>
可重复读指的是一个事务内读取同一数据，数据不一致的情况，原因是读不加锁的话，另一个事务可以在前一个事务读取的过程中修改这个数据。
2. InnoDB锁机制
    * 两段锁
因为有大量的并发访问，为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。<br>
数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）
        - 加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。
        - 解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。
      
      例子如下：
        事务  |加锁/解锁处理
        ------------- | -------------
        begin；|
        insert into test .....|加insert对应的锁
        update test set...|加update对应的锁
        delete from test ....|加delete对应的锁
        commit;|事务提交时，同时释放insert、update、delete对应的锁


    * 不可重复读和幻读区别
不可重复读重点在于update和delete，而幻读的重点在于insert。<br>
&emsp;&emsp;如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。<br>
&emsp;&emsp;MySQL使用了以乐观锁为理论基础的MVCC（多版本并发控制）来解决幻读问题。
  
    *  隔离级别和锁的关系
在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的；
3. MVCC在MySQL的InnoDB中的实现
    * 快照读
在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：
        * SELECT时，读取创建版本号<=当前事务版本号，删除版本号为空或>当前事务版本号。
        * INSERT时，保存当前事务版本号为行的创建版本号
        * DELETE时，保存当前事务版本号为行的删除版本号
        * UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行

        MVCC在RR级别中，通过MVCC机制，虽然让数据变得可重复读，但我们读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)，而读取数据库当前版本数据的方式，叫当前读 (current read)。
    * 当前读
快照读就是简单select，当前读是特殊的读操作，插入/更新/删除/select lock in share mode/select for udate操作，属于当前读，处理的都是当前的数据，需要加锁。为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁。<br>
Next-Key锁<br>
Next-Key锁是行锁和GAP（间隙锁）的合并，行锁上文已经介绍了，接下来说下GAP间隙锁。<br>
行锁可以防止不同事务版本的数据修改提交时造成数据冲突的情况。但如何避免别的事务插入数据就成了问题，这个就需要间隙锁。

    * 总结
行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。



###三、分布式事务
####*模型*
1. Master-slave模型
对于这种加构，Slave一般是Master的备份。在这样的系统中，一般是如下设计的：
    *	读写请求都由Master负责。
    *	写请求写到Master上后，由Master同步到Slave上。

    从Master同步到Slave上，你可以使用异步，也可以使用同步，可以使用Master来push，也可以使用Slave来pull。 通常来说是Slave来周期性的pull，所以，是最终一致性。

2. Master-Master模型
指一个系统存在两个或多个Master，每个Master都提供read-write服务。数据间同步一般是通过Master间的异步完成，所以是最终一致性。

####*2/3阶段提交*
&emsp;&emsp;在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。 两阶段提交的算法如下：

第一阶段：

* 协调者会问所有的参与者结点，是否可以执行提交操作。
* 各个参与者开始事务执行的准备工作：如：为资源上锁，预留资源，写undo/redo log……
* 参与者响应协调者，如果事务的准备工作成功，则回应“可以提交”，否则回应“拒绝提交”。

第二阶段：

* 如果所有的参与者都回应“可以提交”，那么，协调者向所有的参与者发送“正式提交”的命令。参与者完成正式提交，并释放所有资源，然后回应“完成”，协调者收集各结点的“完成”回应后结束这个Global Transaction。
* 如果有一个参与者回应“拒绝提交”，那么，协调者向所有的参与者发送“回滚操作”，并释放所有资源，然后回应“回滚完成”，协调者收集各结点的“回滚”回应后，取消这个Global Transaction。

2PC就是第一阶段做Vote，第二阶段做决定的一个算法，也可以看到2PC这个事是强一致性的算法。

2PC问题:

* 其中一个是同步阻塞操作，这个事情必然会非常大地影响性能。 
* 从两阶段提交的工作方式来看，很显然，在提交事务的过程中需要在多个节点之间进行协调，而各节点对锁资源的释放必须等到事务最终提交时，事务执行时间的延长，锁资源发生冲突的概率增加
* 另一个主要的问题是在TimeOut上

&emsp;&emsp;3PC主要是把二段提交的第一个段break成了两段：询问，然后再锁资源。最后真正提交。三段提交的核心理念是：在询问的时候并不锁定资源，除非所有人都同意了，才开始锁资源。

支付宝使用的是一个二段式的分布式事务 

* 第一阶段，通知各子系统进行业务的操作，比如可以在交易系统中对交易记录表拷贝一个副表，在副表中插入交易记录。如果执行成功，子系统返回成功的信息 
在这个中间还有一个很重要的角色就是有一个总调度者，他负责控制整个事务的流程。发起事务时首先要注册到调度者上，事务完成，或者回滚也是由调度者发起！ 
* 接着上面的继续，当子系统第一阶段业务执行成功，返回成功给调度者，如果所有子系统都返回成功信息，调度者通知子系统进行第二阶段的操作，将数据插入主表中，如果有任何一个子系统返回失败的消息，则通知所有系统回滚。 

&emsp;&emsp;这是一个理想的状态，前提是每次业务操作都会完成，这样事务的一致性就可以保证，但是实际情况不是这样，比如服务器宕机，网络断掉等，会导致某一阶段不能完成。这样会导致事务的不完整，所以我们还需要一个清道夫式的角色，来保证系统中事务的完整。实际上我们可以创建一个定时钟，定时去扫描所有的事务，遇到超时，或者不完整的事务，一律通知各子系统进行回滚，这样虽然有可能会导致误杀一些执行时间过长的事务，但是却保证了整个系统的事务一致，所以还是值得的。


####*Paxos算法*
&emsp;&emsp;Paxos协议用于解决多个节点之间的一致性问题。多个节点之间通过操作日志同步数据，如果只有一个节点为主节点，那么，很容易确保多个节点之间操作日志的一致性。考虑到主节点可能出现故障，系统需要选举出新的主节点。Paxos协议正是用来实现这个需求。

过程如下：

* 准备（prepare）：Proposer首先选择一个提议序号n给其他的acceptor节点发送prepare消息。Acceptor收到prepare消息后，如果提议的序号大于他已经回复的所有prepare消息，则acceptor将自己上次接受的提议回复给proposer，并承诺不再回复小于n的提议。
* 批准（accept）：Proposer收到了acceptor中的多数派对prepare的回复后，就进入批准阶段。如果在之前的prepare阶段acceptor回复了上次接受的提议，那么，proposer选择其中序号最大的提议值发给acceptor批准；否则，proposer生成一个新的提议值发给acceptor批准。Acceptor在不违背他之前在prepare阶段的承诺的前提下，接受这个请求。
* 确认（acknowledge）：如果超过一半的acceptor接受，提议值生效。Proposer发送acknowledge消息通知所有的acceptor提议生效。


####*NWR模型*
&emsp;&emsp;所谓NWR模型。N代表N个备份，W代表要写入至少W份才认为成功，R表示至少读取R个备份。配置的时候要求W+R > N。 因为W+R > N， 所以 R > N-W 这个是什么意思呢？就是读取的份数一定要比总备份数减去确保写成功的倍数的差值要大。<br>
也就是说，每次读取，都至少读取到一个最新的版本。


###四、一致性
####*CAP理论*
####*一致性分类*


###五、MySql
####*undo log、redo log和checkpoint*
####*ACID*
####*分库分表*

##操作系统篇
---
###一、进程&线程
####**
####**
###二、处理器调度
####**
###三、同步、通信与死锁
####**
####**
###四、存储管理
####**
####**

###五、设备管理
####**
####**

###六、文件管理
####**
####**

##网络篇
---
###一、TCP/IP
####**
####**
####**

###二、UDP
####**

##Linux系统篇
---
###一、进程间通信
####**
####**

###二、套接字编程
###三、Linux同步与互斥
###四、Linux I/O模型
###五、Linux 基本命令

##C++篇
---
###一、对象模型
####1. 

###二、多线程内存模型
###三、面向对象
###四、泛型&模板编程
###五、语言特性

##Java篇
---
###一、Java并发编程
###二、语言特性
####1. GC 
####2. Concurrency包
####3. 集合类
####4. 异常处理 

##简历篇
---




